# ğŸŒŠ æµå¼ RAG é—®ç­”ç³»ç»Ÿ

ä¸€ä¸ªåŸºäº LangChain çš„æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒæµå¼å“åº”ã€æç¤ºè¯è§£è€¦ã€å¤šæ¨¡å¼æ£€ç´¢ç­‰ä¼ä¸šçº§ç‰¹æ€§ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸš€ æµå¼å“åº”ç³»ç»Ÿ

- **çœŸæ­£çš„æµå¼è¾“å‡º**ï¼šåªæœ‰ç­”æ¡ˆç”Ÿæˆé˜¶æ®µæ˜¯æµå¼çš„ï¼Œé¿å…ä¸å¿…è¦çš„å»¶è¿Ÿ
- **æ™ºèƒ½æµå¼æ£€æµ‹**ï¼šè‡ªåŠ¨æ£€æµ‹ LLM æ˜¯å¦æ”¯æŒæµå¼è°ƒç”¨ï¼ˆ`astream`ï¼‰
- **ä¼˜é›…é™çº§**ï¼šä¸æ”¯æŒæµå¼æ—¶è‡ªåŠ¨å›é€€åˆ°æ¨¡æ‹Ÿæµå¼è¾“å‡º
- **å®æ—¶çŠ¶æ€æ›´æ–°**ï¼šå¤„ç†è¿‡ç¨‹ä¸­æä¾›æ¸…æ™°çš„çŠ¶æ€åé¦ˆ

### ğŸ”§ æç¤ºè¯ç®¡ç†ç³»ç»Ÿ

- **å®Œå…¨è§£è€¦**ï¼šæç¤ºè¯ä¸ä»£ç  100%åˆ†ç¦»ï¼Œå­˜å‚¨åœ¨ç‹¬ç«‹çš„`.txt`æ–‡ä»¶ä¸­
- **ç¼“å­˜æœºåˆ¶**ï¼šå†…ç½®ç¼“å­˜æé«˜æ€§èƒ½ï¼Œé¿å…é‡å¤æ–‡ä»¶è¯»å–
- **åŠ¨æ€é‡è½½**ï¼šæ”¯æŒè¿è¡Œæ—¶æ›´æ–°æç¤ºè¯ï¼Œæ— éœ€é‡å¯æœåŠ¡
- **ç»Ÿä¸€ç®¡ç†**ï¼šé›†ä¸­ç®¡ç†æ‰€æœ‰æç¤ºè¯ï¼Œä¾¿äºç‰ˆæœ¬æ§åˆ¶å’Œå›¢é˜Ÿåä½œ

### ğŸ¯ å¤šæ¨¡å¼ RAG æµç¨‹

- **åŒæ­¥æ¨¡å¼**ï¼š`RagPipeline` - ä¼ ç»ŸåŒæ­¥å¤„ç†
- **å¼‚æ­¥æ¨¡å¼**ï¼š`AsyncRagPipeline` - é«˜å¹¶å‘å¼‚æ­¥å¤„ç†
- **æµå¼æ¨¡å¼**ï¼š`StreamingRagPipeline` - å®æ—¶æµå¼å“åº”

### ğŸ” æ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ

- **æ··åˆæ£€ç´¢**ï¼šå‘é‡æ£€ç´¢ + BM25 å…³é”®å­—æ£€ç´¢
- **æ™ºèƒ½é‡æ’åº**ï¼šä½¿ç”¨ CrossEncoder æ¨¡å‹æé«˜æ£€ç´¢ç²¾åº¦
- **é—®é¢˜æ”¹å†™**ï¼šè‡ªåŠ¨ç”Ÿæˆå¤šä¸ªç›¸å…³é—®é¢˜æé«˜æ£€ç´¢è¦†ç›–é¢
- **åˆ†ç±»æ£€ç´¢**ï¼šæ”¯æŒæŒ‰æ–‡æ¡£ç±»åˆ«è¿›è¡Œç²¾å‡†æ£€ç´¢

### ğŸ“Š ä¼ä¸šçº§æ•°æ®ç®¡ç†

- **æ™ºèƒ½åŒæ­¥**ï¼šè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶å˜åŒ–ï¼Œå¢é‡æ›´æ–°å‘é‡æ•°æ®åº“
- **å¤šæ•°æ®æº**ï¼šæ”¯æŒå¤šä¸ªæ•°æ®æºçš„åˆ†ç±»ç®¡ç†
- **æ–‡ä»¶ç›‘æ§**ï¼šåŸºäºæ–‡ä»¶å“ˆå¸Œçš„å˜æ›´æ£€æµ‹
- **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒå¤§è§„æ¨¡æ–‡æ¡£çš„å¹¶å‘å¤„ç†

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
rag_example/
â”œâ”€â”€ rag/                          # æ ¸å¿ƒRAGæ¨¡å—
â”‚   â”œâ”€â”€ prompts/                  # æç¤ºè¯ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ qa_prompt.txt         # é—®ç­”æç¤ºè¯
â”‚   â”‚   â”œâ”€â”€ query_rewrite_prompt.txt # é—®é¢˜æ”¹å†™æç¤ºè¯
â”‚   â”‚   â””â”€â”€ README.md             # æç¤ºè¯ä½¿ç”¨è¯´æ˜
â”‚   â”œâ”€â”€ config.py                 # ç³»ç»Ÿé…ç½®
â”‚   â”œâ”€â”€ prompt_manager.py         # æç¤ºè¯ç®¡ç†å™¨
â”‚   â”œâ”€â”€ pipeline.py               # åŒæ­¥RAGæµç¨‹
â”‚   â”œâ”€â”€ async_pipeline.py         # å¼‚æ­¥RAGæµç¨‹
â”‚   â””â”€â”€ streaming_pipeline.py     # æµå¼RAGæµç¨‹
â”œâ”€â”€ streaming_web_demo.py         # Webæ¼”ç¤ºåº”ç”¨
â”œâ”€â”€ prompt_management_api.py      # æç¤ºè¯ç®¡ç†APIæœåŠ¡
â”œâ”€â”€ demo_runtime_prompt_update.py # è¿è¡Œæ—¶æ›´æ–°æ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ test_prompt_manager.py        # æç¤ºè¯ç®¡ç†å™¨æµ‹è¯•
â”œâ”€â”€ verify_prompt_decoupling.py   # è§£è€¦éªŒè¯è„šæœ¬
â””â”€â”€ README.md                     # é¡¹ç›®æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# ä½¿ç”¨uvå®‰è£…ä¾èµ–ï¼ˆæ¨èï¼‰
uv sync

# æˆ–è€…ä»requirements.txtå®‰è£…
uv pip install -r requirements.txt

# é…ç½®ç¯å¢ƒå˜é‡ï¼ˆåˆ›å»º .env æ–‡ä»¶ï¼‰
DeepSeek_api_key=your_api_key_here
DeepSeek_base_url=https://api.deepseek.com
DeepSeek_model_name=deepseek-chat
```

### 2. æ•°æ®å‡†å¤‡

```bash
# å°†æ–‡æ¡£æ”¾å…¥ data ç›®å½•
mkdir -p data
cp your_documents.txt data/

# åŒæ­¥æ•°æ®åˆ°å‘é‡æ•°æ®åº“
uv run main.py
```

### 3. å¯åŠ¨ Web æ¼”ç¤º

```bash
# å¯åŠ¨æµå¼Webæ¼”ç¤º
uv run streaming_web_demo.py

# è®¿é—® http://localhost:8000
```

## ğŸ’» ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€é—®ç­”

```python
from rag.pipeline import RagPipeline

# åˆå§‹åŒ–RAGç³»ç»Ÿ
rag = RagPipeline()

# åŒæ­¥æ•°æ®
rag.sync_data_directory()

# é—®ç­”
result = rag.ask("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
print(result['result'])
```

### å¼‚æ­¥é—®ç­”

```python
import asyncio
from rag.async_pipeline import AsyncRagPipeline

async def main():
    # åˆå§‹åŒ–å¼‚æ­¥RAGç³»ç»Ÿ
    rag = AsyncRagPipeline()

    # å¼‚æ­¥åŒæ­¥æ•°æ®
    await rag.sync_data_directory_async()

    # å¼‚æ­¥é—®ç­”
    result = await rag.ask_async("ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ")
    print(result['result'])

asyncio.run(main())
```

### æµå¼é—®ç­”

```python
import asyncio
from rag.streaming_pipeline import StreamingRagPipeline

async def main():
    # åˆå§‹åŒ–æµå¼RAGç³»ç»Ÿ
    rag = StreamingRagPipeline()

    # æµå¼é—®ç­”
    async for event in rag.ask_stream("è§£é‡Šä¸€ä¸‹ç¥ç»ç½‘ç»œ"):
        if event.type.value == "generation_chunk":
            print(event.data["chunk"], end="", flush=True)
        elif event.type.value == "processing":
            print(f"\nğŸ” {event.data['message']}")

asyncio.run(main())
```

### åˆ†ç±»æ£€ç´¢

```python
# æŒ‰ç±»åˆ«æ£€ç´¢
result = rag.ask_with_categories(
    question="æœºå™¨å­¦ä¹ çš„åº”ç”¨åœºæ™¯",
    categories=["æŠ€æœ¯æ–‡æ¡£", "æ•™ç¨‹"]
)
```

### æç¤ºè¯ç®¡ç†

```python
from rag.prompt_manager import prompt_manager

# åˆ—å‡ºæ‰€æœ‰æç¤ºè¯
prompts = prompt_manager.list_available_prompts()
print(f"å¯ç”¨æç¤ºè¯: {prompts}")

# é‡æ–°åŠ è½½æç¤ºè¯
prompt_manager.reload_prompt("qa_prompt")

# ä¿å­˜æ–°æç¤ºè¯
prompt_manager.save_prompt("custom_prompt", "è‡ªå®šä¹‰æç¤ºè¯å†…å®¹")
```

## ğŸ”§ é…ç½®è¯´æ˜

### æ ¸å¿ƒé…ç½® (`rag/config.py`)

```python
# æ¨¡å‹é…ç½®
EMBEDDING_MODEL_NAME = "BAAI/bge-small-zh-v1.5"
RERANKER_MODEL_NAME = "BAAI/bge-reranker-base"

# æ£€ç´¢é…ç½®
RETRIEVER_TOP_K = 5
RERANKER_TOP_N = 3
ENABLE_HYBRID_SEARCH = True

# æµå¼é…ç½®
ENABLE_QUERY_REWRITING = True
QUERY_REWRITE_COUNT = 3

# ä¼ä¸šçº§é…ç½®
ENABLE_ENTERPRISE_MODE = False
ENTERPRISE_DATA_SOURCES = {
    "docs": {
        "path": "data/docs",
        "category": "documentation",
        "description": "æŠ€æœ¯æ–‡æ¡£",
        "file_patterns": ["*.txt", "*.md"]
    }
}
```

### æç¤ºè¯é…ç½®

ç›´æ¥ç¼–è¾‘ `rag/prompts/` ç›®å½•ä¸‹çš„ `.txt` æ–‡ä»¶ï¼š

```bash
# ä¿®æ”¹é—®ç­”æç¤ºè¯
vim rag/prompts/qa_prompt.txt

# ä¿®æ”¹é—®é¢˜æ”¹å†™æç¤ºè¯
vim rag/prompts/query_rewrite_prompt.txt
```

## ğŸŒ Web æ¼”ç¤ºç‰¹æ€§

### å®æ—¶æµå¼ç•Œé¢

- **WebSocket è¿æ¥**ï¼šå®æ—¶åŒå‘é€šä¿¡
- **æµå¼æ˜¾ç¤º**ï¼šç­”æ¡ˆé€å­—ç¬¦å®æ—¶æ˜¾ç¤º
- **çŠ¶æ€åé¦ˆ**ï¼šå¤„ç†è¿‡ç¨‹å¯è§†åŒ–
- **è‡ªåŠ¨é‡è¿**ï¼šè¿æ¥æ–­å¼€è‡ªåŠ¨æ¢å¤

### ç”¨æˆ·ä½“éªŒä¼˜åŒ–

- **å“åº”å¼è®¾è®¡**ï¼šé€‚é…ä¸åŒå±å¹•å°ºå¯¸
- **è¿æ¥çŠ¶æ€æ˜¾ç¤º**ï¼šå®æ—¶æ˜¾ç¤ºè¿æ¥çŠ¶æ€
- **é”™è¯¯å¤„ç†**ï¼šå‹å¥½çš„é”™è¯¯æç¤º
- **é”®ç›˜å¿«æ·é”®**ï¼šæ”¯æŒå›è½¦å‘é€

## ğŸ”§ æç¤ºè¯è¿è¡Œæ—¶ç®¡ç†

### æ¼”ç¤ºè„šæœ¬ä½¿ç”¨

```bash
# è¿è¡Œå®Œæ•´çš„è¿è¡Œæ—¶æ›´æ–°æ¼”ç¤º
uv run demo_runtime_prompt_update.py
```

**æ¼”ç¤ºåŠŸèƒ½åŒ…æ‹¬ï¼š**

- âœ… æ˜¾ç¤ºå½“å‰æç¤ºè¯å†…å®¹å’Œä½¿ç”¨æ•ˆæœ
- âœ… è¿è¡Œæ—¶æ›´æ–°æç¤ºè¯å†…å®¹
- âœ… éªŒè¯æ›´æ–°åçš„æ•ˆæœï¼ˆæ— éœ€é‡å¯æœåŠ¡ï¼‰
- âœ… æ¼”ç¤ºæ‰‹åŠ¨é‡è½½åŠŸèƒ½
- âœ… è‡ªåŠ¨æ¢å¤åŸå§‹æç¤ºè¯

### Web ç®¡ç†ç•Œé¢

```bash
# å¯åŠ¨æç¤ºè¯ç®¡ç†APIæœåŠ¡
uv run prompt_management_api.py

# è®¿é—®ç®¡ç†ç•Œé¢: http://localhost:8001
# APIæ–‡æ¡£: http://localhost:8001/docs
```

**Web ç•Œé¢åŠŸèƒ½ï¼š**

- ğŸ¯ **å¯è§†åŒ–ç®¡ç†**ï¼šæŸ¥çœ‹æ‰€æœ‰æç¤ºè¯çš„çŠ¶æ€å’Œå†…å®¹
- âœï¸ **åœ¨çº¿ç¼–è¾‘**ï¼šç›´æ¥åœ¨ Web ç•Œé¢ç¼–è¾‘æç¤ºè¯
- ğŸ’¾ **å®æ—¶ä¿å­˜**ï¼šä¿å­˜åç«‹å³ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯æœåŠ¡
- ğŸ”„ **é‡è½½åŠŸèƒ½**ï¼šæ‰‹åŠ¨é‡è½½å•ä¸ªæˆ–æ‰€æœ‰æç¤ºè¯
- âœ… **éªŒè¯åŠŸèƒ½**ï¼šæ£€æŸ¥æç¤ºè¯æ ¼å¼å’Œå˜é‡
- â• **åˆ›å»ºæ–°æç¤ºè¯**ï¼šåœ¨çº¿åˆ›å»ºæ–°çš„æç¤ºè¯æ–‡ä»¶
- ğŸ“‹ **æ›´æ–°å†å²**ï¼šæŸ¥çœ‹æ‰€æœ‰æ›´æ–°æ“ä½œè®°å½•

### API æ¥å£ä½¿ç”¨

```bash
# è·å–æ‰€æœ‰æç¤ºè¯
curl http://localhost:8001/api/prompts

# è·å–ç‰¹å®šæç¤ºè¯
curl http://localhost:8001/api/prompts/qa_prompt

# æ›´æ–°æç¤ºè¯
curl -X PUT http://localhost:8001/api/prompts/qa_prompt \
  -H "Content-Type: application/json" \
  -d '{"content": "æ–°çš„æç¤ºè¯å†…å®¹ {context} {question}", "description": "APIæ›´æ–°"}'

# é‡è½½æç¤ºè¯
curl -X POST http://localhost:8001/api/prompts/qa_prompt/reload

# éªŒè¯æç¤ºè¯
curl http://localhost:8001/api/prompts/qa_prompt/validate

# æ‰¹é‡é‡è½½æ‰€æœ‰æç¤ºè¯
curl -X POST http://localhost:8001/api/prompts/reload-all
```

### å®é™…åº”ç”¨åœºæ™¯

#### åœºæ™¯ 1ï¼šåŒæ—¶è¿è¡Œ RAG æœåŠ¡å’Œç®¡ç†ç•Œé¢

```bash
# ç»ˆç«¯1ï¼šå¯åŠ¨RAG Webæ¼”ç¤º
uv run streaming_web_demo.py &

# ç»ˆç«¯2ï¼šå¯åŠ¨æç¤ºè¯ç®¡ç†
uv run prompt_management_api.py

# ç°åœ¨ä½ å¯ä»¥ï¼š
# 1. åœ¨ http://localhost:8000 æµ‹è¯•é—®ç­”æ•ˆæœ
# 2. åœ¨ http://localhost:8001 ä¿®æ”¹æç¤ºè¯
# 3. ä¿®æ”¹åç«‹å³åœ¨é—®ç­”ç•Œé¢çœ‹åˆ°æ•ˆæœå˜åŒ–
```

#### åœºæ™¯ 2ï¼šA/B æµ‹è¯•ä¸åŒæç¤ºè¯

```python
# åˆ›å»ºæµ‹è¯•è„šæœ¬ test_prompts.py
import requests

# ç‰ˆæœ¬Aï¼šä¸¥è°¨é£æ ¼
prompt_a = "è¯·ä¸¥æ ¼æŒ‰ç…§æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜..."

# ç‰ˆæœ¬Bï¼šå‹å¥½é£æ ¼
prompt_b = "è¯·ç”¨å‹å¥½äº²åˆ‡çš„è¯­æ°”å›ç­”ç”¨æˆ·é—®é¢˜..."

# åˆ‡æ¢åˆ°ç‰ˆæœ¬Aå¹¶æµ‹è¯•
requests.put("http://localhost:8001/api/prompts/qa_prompt",
            json={"content": prompt_a, "description": "æµ‹è¯•ä¸¥è°¨é£æ ¼"})

# åˆ‡æ¢åˆ°ç‰ˆæœ¬Bå¹¶æµ‹è¯•
requests.put("http://localhost:8001/api/prompts/qa_prompt",
            json={"content": prompt_b, "description": "æµ‹è¯•å‹å¥½é£æ ¼"})
```

```bash
# è¿è¡ŒA/Bæµ‹è¯•
uv run test_prompts.py
```

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### è¿è¡Œæµ‹è¯•

```bash
# æµ‹è¯•æç¤ºè¯ç®¡ç†å™¨
uv run test_prompt_manager.py

# éªŒè¯æç¤ºè¯è§£è€¦
uv run verify_prompt_decoupling.py
```

### æ€§èƒ½æµ‹è¯•

```bash
# è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
uv run -c "
import time
import asyncio
from rag.streaming_pipeline import StreamingRagPipeline

async def benchmark():
    rag = StreamingRagPipeline()

    questions = [
        'ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ',
        'æ·±åº¦å­¦ä¹ çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ',
        'ç¥ç»ç½‘ç»œå¦‚ä½•å·¥ä½œï¼Ÿ'
    ]

    start_time = time.time()

    # æ‰¹é‡æµå¼å¤„ç†
    async for event in rag.batch_ask_stream(questions):
        if event.type.value == 'complete':
            break

    end_time = time.time()
    print(f'å¤„ç† {len(questions)} ä¸ªé—®é¢˜è€—æ—¶: {end_time - start_time:.2f}ç§’')

asyncio.run(benchmark())
"
```

## ğŸ” æ ¸å¿ƒæŠ€æœ¯

### æµå¼å“åº”è®¾è®¡ç†å¿µ

```python
# âœ… æ­£ç¡®çš„æµå¼è®¾è®¡
async def ask_stream(self, question: str):
    # 1. éæµå¼å¤„ç†é˜¶æ®µ
    yield StreamEvent(type="processing", data={"message": "æ£€ç´¢æ–‡æ¡£..."})
    docs = await self.retrieve_documents(question)

    # 2. æµå¼ç”Ÿæˆé˜¶æ®µ
    yield StreamEvent(type="generation_start")
    if hasattr(self.llm, 'astream'):
        # çœŸæ­£çš„LLMæµå¼è°ƒç”¨
        async for chunk in self.llm.astream(prompt):
            yield StreamEvent(type="generation_chunk", data={"chunk": chunk.content})
    else:
        # ä¼˜é›…é™çº§åˆ°æ¨¡æ‹Ÿæµå¼
        response = await self.llm.ainvoke(prompt)
        for char in response.content:
            yield StreamEvent(type="generation_chunk", data={"chunk": char})

    yield StreamEvent(type="generation_end")
```

### æç¤ºè¯è§£è€¦æ¶æ„

```python
# æç¤ºè¯ç®¡ç†å™¨è®¾è®¡
class PromptManager:
    def __init__(self):
        self.prompts_dir = Path(__file__).parent / "prompts"
        self._prompt_cache = {}  # ç¼“å­˜æœºåˆ¶
        self._template_cache = {}

    def get_template(self, prompt_name: str) -> PromptTemplate:
        # ç¼“å­˜æ£€æŸ¥ -> æ–‡ä»¶åŠ è½½ -> æ¨¡æ¿åˆ›å»º -> ç¼“å­˜å­˜å‚¨
        if prompt_name in self._template_cache:
            return self._template_cache[prompt_name]

        content = self.load_prompt(prompt_name)
        template = PromptTemplate.from_template(content)
        self._template_cache[prompt_name] = template
        return template
```

### æ™ºèƒ½æ£€ç´¢æµç¨‹

```python
# æ··åˆæ£€ç´¢ + é‡æ’åº
def _build_hybrid_retriever(self):
    # 1. å‘é‡æ£€ç´¢å™¨
    vector_retriever = self.vector_store.as_retriever(k=5)

    # 2. BM25å…³é”®å­—æ£€ç´¢å™¨
    bm25_retriever = BM25Retriever.from_documents(
        self.all_documents,
        preprocess_func=lambda text: list(jieba.cut(text))
    )

    # 3. æ··åˆæ£€ç´¢å™¨
    ensemble_retriever = EnsembleRetriever(
        retrievers=[vector_retriever, bm25_retriever],
        weights=[0.7, 0.3]
    )

    # 4. é‡æ’åºå™¨
    compression_retriever = ContextualCompressionRetriever(
        base_compressor=self.reranker,
        base_retriever=ensemble_retriever
    )

    return compression_retriever
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜ç­–ç•¥

- **æç¤ºè¯ç¼“å­˜**ï¼šé¿å…é‡å¤æ–‡ä»¶è¯»å–
- **æ–‡æ¡£ç¼“å­˜**ï¼šæ™ºèƒ½æ–‡æ¡£å˜æ›´æ£€æµ‹
- **æ¨¡å‹ç¼“å­˜**ï¼šå¤ç”¨å·²åŠ è½½çš„æ¨¡å‹

### å¹¶å‘ä¼˜åŒ–

- **å¼‚æ­¥å¤„ç†**ï¼šå…¨é¢æ”¯æŒå¼‚æ­¥æ“ä½œ
- **çº¿ç¨‹æ± **ï¼šCPU å¯†é›†å‹ä»»åŠ¡ä½¿ç”¨çº¿ç¨‹æ± 
- **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒé—®é¢˜æ‰¹é‡å¹¶å‘å¤„ç†

### å†…å­˜ä¼˜åŒ–

- **å¢é‡æ›´æ–°**ï¼šåªå¤„ç†å˜æ›´çš„æ–‡æ¡£
- **åˆ†å—å¤„ç†**ï¼šå¤§æ–‡æ¡£è‡ªåŠ¨åˆ†å—
- **åƒåœ¾å›æ”¶**ï¼šåŠæ—¶æ¸…ç†ä¸ç”¨çš„èµ„æº

## ğŸ› ï¸ æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„æç¤ºè¯

```bash
# 1. åˆ›å»ºæç¤ºè¯æ–‡ä»¶
echo "æ–°çš„æç¤ºè¯å†…å®¹ {variable}" > rag/prompts/new_prompt.txt

# 2. åœ¨ prompt_manager.py ä¸­æ·»åŠ è¾…åŠ©å‡½æ•°
def get_new_prompt_template():
    return prompt_manager.get_template("new_prompt")

# 3. åœ¨ä¸šåŠ¡ä»£ç ä¸­ä½¿ç”¨
uv run -c "
from rag.prompt_manager import get_new_prompt_template
template = get_new_prompt_template()
print(template.format(variable='test'))
"
```

### è‡ªå®šä¹‰æ£€ç´¢å™¨

```python
class CustomRetriever:
    def __init__(self, vector_store):
        self.vector_store = vector_store

    def get_relevant_documents(self, query: str):
        # è‡ªå®šä¹‰æ£€ç´¢é€»è¾‘
        return self.vector_store.similarity_search(query, k=10)

# é›†æˆåˆ°RAGæµç¨‹
rag.custom_retriever = CustomRetriever(rag.vector_store)
```

### æ–°å¢æµå¼äº‹ä»¶ç±»å‹

```python
class StreamEventType(Enum):
    PROCESSING = "processing"
    GENERATION_START = "generation_start"
    GENERATION_CHUNK = "generation_chunk"
    GENERATION_END = "generation_end"
    ERROR = "error"
    COMPLETE = "complete"
    # æ–°å¢äº‹ä»¶ç±»å‹
    CUSTOM_EVENT = "custom_event"
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. **Fork** é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ï¼š`git checkout -b feature/amazing-feature`
3. æäº¤æ›´æ”¹ï¼š`git commit -m 'Add amazing feature'`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/amazing-feature`
5. æäº¤ **Pull Request**

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [LangChain](https://github.com/langchain-ai/langchain) - å¼ºå¤§çš„ LLM åº”ç”¨æ¡†æ¶
- [ChromaDB](https://github.com/chroma-core/chroma) - é«˜æ€§èƒ½å‘é‡æ•°æ®åº“
- [FastAPI](https://github.com/tiangolo/fastapi) - ç°ä»£åŒ–çš„ Web æ¡†æ¶
- [HuggingFace](https://huggingface.co/) - ä¼˜ç§€çš„æ¨¡å‹ç”Ÿæ€

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- ğŸ“§ Email: [your-email@example.com]
- ğŸ› Issues: [GitHub Issues](https://github.com/your-repo/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/your-repo/discussions)

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼
