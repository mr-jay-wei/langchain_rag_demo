# test_correct_streaming.py - æ­£ç¡®æµå¼å“åº”æµ‹è¯•

import asyncio
import time
from typing import AsyncGenerator
from dataclasses import dataclass
from enum import Enum


class StreamEventType(Enum):
    PROCESSING = "processing"
    GENERATION_START = "generation_start"
    GENERATION_CHUNK = "generation_chunk"
    GENERATION_END = "generation_end"
    COMPLETE = "complete"


@dataclass
class StreamEvent:
    type: StreamEventType
    data: dict
    timestamp: float


async def simulate_rag_processing() -> str:
    """æ¨¡æ‹ŸRAGçš„å†…éƒ¨å¤„ç†è¿‡ç¨‹ï¼ˆé—®é¢˜æ”¹å†™ã€æ£€ç´¢ã€é‡æ’åºç­‰ï¼‰"""
    await asyncio.sleep(2.0)  # æ¨¡æ‹Ÿ2ç§’çš„å¤„ç†æ—¶é—´
    return "æ ¹æ®æä¾›çš„èµ„æ–™ï¼Œæœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚"


async def wrong_streaming_approach(question: str) -> AsyncGenerator[StreamEvent, None]:
    """âŒ é”™è¯¯çš„æµå¼æ–¹æ³•ï¼šä¸­é—´è¿‡ç¨‹ä¹Ÿæµå¼"""
    print("âŒ é”™è¯¯æ–¹æ³•ï¼šä¸­é—´è¿‡ç¨‹ä¹Ÿæµå¼")
    
    # é—®é¢˜æ”¹å†™é˜¶æ®µ - æµå¼äº‹ä»¶
    yield StreamEvent(
        type=StreamEventType.PROCESSING,
        data={"message": "æ­£åœ¨æ”¹å†™é—®é¢˜..."},
        timestamp=time.time()
    )
    await asyncio.sleep(0.3)
    
    yield StreamEvent(
        type=StreamEventType.PROCESSING,
        data={"message": "é—®é¢˜æ”¹å†™å®Œæˆï¼Œç”Ÿæˆäº†3ä¸ªæŸ¥è¯¢é—®é¢˜"},
        timestamp=time.time()
    )
    
    # æ£€ç´¢é˜¶æ®µ - æµå¼äº‹ä»¶
    yield StreamEvent(
        type=StreamEventType.PROCESSING,
        data={"message": "æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£..."},
        timestamp=time.time()
    )
    await asyncio.sleep(0.5)
    
    yield StreamEvent(
        type=StreamEventType.PROCESSING,
        data={"message": "æ£€ç´¢å®Œæˆï¼Œè·å¾—8ä¸ªç›¸å…³æ–‡æ¡£"},
        timestamp=time.time()
    )
    
    # é‡æ’åºé˜¶æ®µ - æµå¼äº‹ä»¶
    yield StreamEvent(
        type=StreamEventType.PROCESSING,
        data={"message": "æ­£åœ¨é‡æ’åº..."},
        timestamp=time.time()
    )
    await asyncio.sleep(0.2)
    
    yield StreamEvent(
        type=StreamEventType.PROCESSING,
        data={"message": "é‡æ’åºå®Œæˆï¼Œé€‰æ‹©3ä¸ªæœ€ç›¸å…³æ–‡æ¡£"},
        timestamp=time.time()
    )
    
    # ç”Ÿæˆç­”æ¡ˆ - ç­‰å¾…å®Œæˆåå†æµå¼è¾“å‡º
    answer = await simulate_rag_processing()
    
    yield StreamEvent(
        type=StreamEventType.GENERATION_START,
        data={"message": "å¼€å§‹ç”Ÿæˆç­”æ¡ˆ"},
        timestamp=time.time()
    )
    
    # æµå¼è¾“å‡ºç­”æ¡ˆ
    for i, char in enumerate(answer):
        await asyncio.sleep(0.02)
        yield StreamEvent(
            type=StreamEventType.GENERATION_CHUNK,
            data={"chunk": char},
            timestamp=time.time()
        )
    
    yield StreamEvent(
        type=StreamEventType.GENERATION_END,
        data={"message": "ç­”æ¡ˆç”Ÿæˆå®Œæˆ"},
        timestamp=time.time()
    )


async def correct_streaming_approach(question: str) -> AsyncGenerator[StreamEvent, None]:
    """âœ… æ­£ç¡®çš„æµå¼æ–¹æ³•ï¼šåªæœ‰ç­”æ¡ˆç”Ÿæˆæ˜¯æµå¼çš„"""
    print("âœ… æ­£ç¡®æ–¹æ³•ï¼šåªæœ‰ç­”æ¡ˆç”Ÿæˆæµå¼")
    
    # å¤„ç†é˜¶æ®µ - ç®€å•çš„çŠ¶æ€é€šçŸ¥
    yield StreamEvent(
        type=StreamEventType.PROCESSING,
        data={"message": "æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜..."},
        timestamp=time.time()
    )
    
    # å†…éƒ¨å¤„ç†ï¼ˆéæµå¼ï¼‰- å¹¶å‘æ‰§è¡Œæ‰€æœ‰å¤„ç†æ­¥éª¤
    answer = await simulate_rag_processing()
    
    # å¼€å§‹æµå¼ç”Ÿæˆç­”æ¡ˆ
    yield StreamEvent(
        type=StreamEventType.GENERATION_START,
        data={"message": "å¼€å§‹ç”Ÿæˆç­”æ¡ˆ"},
        timestamp=time.time()
    )
    
    # æµå¼è¾“å‡ºç­”æ¡ˆ
    for i, char in enumerate(answer):
        await asyncio.sleep(0.02)
        yield StreamEvent(
            type=StreamEventType.GENERATION_CHUNK,
            data={"chunk": char},
            timestamp=time.time()
        )
    
    yield StreamEvent(
        type=StreamEventType.GENERATION_END,
        data={"message": "ç­”æ¡ˆç”Ÿæˆå®Œæˆ"},
        timestamp=time.time()
    )


async def test_streaming_approaches():
    """æµ‹è¯•ä¸¤ç§æµå¼æ–¹æ³•"""
    print("ğŸŒŠ æµå¼å“åº”æ–¹æ³•å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    question = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
    
    # æµ‹è¯•é”™è¯¯æ–¹æ³•
    print("\n1ï¸âƒ£ æµ‹è¯•é”™è¯¯çš„æµå¼æ–¹æ³•:")
    start_time = time.time()
    first_chunk_time_wrong = None
    generation_start_time_wrong = None
    event_count_wrong = 0
    
    async for event in wrong_streaming_approach(question):
        event_count_wrong += 1
        elapsed = time.time() - start_time
        
        if event.type == StreamEventType.GENERATION_START:
            generation_start_time_wrong = time.time()
            print(f"   ğŸ’­ [{elapsed:.2f}s] å¼€å§‹ç”Ÿæˆç­”æ¡ˆ")
        
        elif event.type == StreamEventType.GENERATION_CHUNK:
            if first_chunk_time_wrong is None:
                first_chunk_time_wrong = time.time()
                first_chunk_elapsed = first_chunk_time_wrong - start_time
                print(f"   âš¡ [{first_chunk_elapsed:.2f}s] é¦–ä¸ªå­—ç¬¦è¾“å‡º")
                print(f"   ğŸ“ ç­”æ¡ˆ: ", end='', flush=True)
            print(event.data.get('chunk', ''), end='', flush=True)
        
        elif event.type == StreamEventType.PROCESSING:
            print(f"   ğŸ”„ [{elapsed:.2f}s] {event.data['message']}")
        
        elif event.type == StreamEventType.GENERATION_END:
            print(f"\n   âœ… [{elapsed:.2f}s] ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
    
    wrong_total_time = time.time() - start_time
    wrong_first_chunk_latency = first_chunk_time_wrong - start_time if first_chunk_time_wrong else 0
    wrong_generation_latency = generation_start_time_wrong - start_time if generation_start_time_wrong else 0
    
    print(f"   ğŸ“Š æ€»è€—æ—¶: {wrong_total_time:.2f}ç§’")
    print(f"   ğŸ“Š æ€»äº‹ä»¶æ•°: {event_count_wrong}")
    print(f"   ğŸ“Š é¦–å­—ç¬¦å»¶è¿Ÿ: {wrong_first_chunk_latency:.2f}ç§’")
    print(f"   ğŸ“Š ç”Ÿæˆå¼€å§‹å»¶è¿Ÿ: {wrong_generation_latency:.2f}ç§’")
    
    # æµ‹è¯•æ­£ç¡®æ–¹æ³•
    print(f"\n2ï¸âƒ£ æµ‹è¯•æ­£ç¡®çš„æµå¼æ–¹æ³•:")
    start_time = time.time()
    first_chunk_time_correct = None
    generation_start_time_correct = None
    event_count_correct = 0
    
    async for event in correct_streaming_approach(question):
        event_count_correct += 1
        elapsed = time.time() - start_time
        
        if event.type == StreamEventType.PROCESSING:
            print(f"   ğŸ”„ [{elapsed:.2f}s] {event.data['message']}")
        
        elif event.type == StreamEventType.GENERATION_START:
            generation_start_time_correct = time.time()
            print(f"   ğŸ’­ [{elapsed:.2f}s] å¼€å§‹ç”Ÿæˆç­”æ¡ˆ")
        
        elif event.type == StreamEventType.GENERATION_CHUNK:
            if first_chunk_time_correct is None:
                first_chunk_time_correct = time.time()
                first_chunk_elapsed = first_chunk_time_correct - start_time
                print(f"   âš¡ [{first_chunk_elapsed:.2f}s] é¦–ä¸ªå­—ç¬¦è¾“å‡º")
                print(f"   ğŸ“ ç­”æ¡ˆ: ", end='', flush=True)
            print(event.data.get('chunk', ''), end='', flush=True)
        
        elif event.type == StreamEventType.GENERATION_END:
            print(f"\n   âœ… [{elapsed:.2f}s] ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
    
    correct_total_time = time.time() - start_time
    correct_first_chunk_latency = first_chunk_time_correct - start_time if first_chunk_time_correct else 0
    correct_generation_latency = generation_start_time_correct - start_time if generation_start_time_correct else 0
    
    print(f"   ğŸ“Š æ€»è€—æ—¶: {correct_total_time:.2f}ç§’")
    print(f"   ğŸ“Š æ€»äº‹ä»¶æ•°: {event_count_correct}")
    print(f"   ğŸ“Š é¦–å­—ç¬¦å»¶è¿Ÿ: {correct_first_chunk_latency:.2f}ç§’")
    print(f"   ğŸ“Š ç”Ÿæˆå¼€å§‹å»¶è¿Ÿ: {correct_generation_latency:.2f}ç§’")
    
    # å¯¹æ¯”åˆ†æ
    print(f"\nğŸ“ˆ å¯¹æ¯”åˆ†æ:")
    print(f"   äº‹ä»¶æ•°é‡å¯¹æ¯”:")
    print(f"     é”™è¯¯æ–¹æ³•: {event_count_wrong} ä¸ªäº‹ä»¶")
    print(f"     æ­£ç¡®æ–¹æ³•: {event_count_correct} ä¸ªäº‹ä»¶")
    print(f"     å‡å°‘: {event_count_wrong - event_count_correct} ä¸ªä¸å¿…è¦äº‹ä»¶")
    
    print(f"\n   ç”¨æˆ·ä½“éªŒå¯¹æ¯”:")
    print(f"     é”™è¯¯æ–¹æ³•é¦–å­—ç¬¦å»¶è¿Ÿ: {wrong_first_chunk_latency:.2f}ç§’")
    print(f"     æ­£ç¡®æ–¹æ³•é¦–å­—ç¬¦å»¶è¿Ÿ: {correct_first_chunk_latency:.2f}ç§’")
    
    if abs(wrong_first_chunk_latency - correct_first_chunk_latency) < 0.1:
        print(f"     âœ… ä¸¤ç§æ–¹æ³•çš„ç”¨æˆ·ä½“éªŒåŸºæœ¬ç›¸åŒ")
    
    print(f"\n   å®ç°å¤æ‚åº¦å¯¹æ¯”:")
    print(f"     é”™è¯¯æ–¹æ³•: éœ€è¦ä¸ºæ¯ä¸ªä¸­é—´æ­¥éª¤è®¾è®¡æµå¼äº‹ä»¶")
    print(f"     æ­£ç¡®æ–¹æ³•: åªéœ€è¦ä¸ºæœ€ç»ˆè¾“å‡ºè®¾è®¡æµå¼")
    print(f"     âœ… æ­£ç¡®æ–¹æ³•æ›´ç®€å•ã€æ›´é«˜æ•ˆ")
    
    print(f"\nğŸ’¡ å…³é”®æ´å¯Ÿ:")
    print(f"   1. ç”¨æˆ·çœŸæ­£å…³å¿ƒçš„æ˜¯çœ‹åˆ°ç­”æ¡ˆé€æ­¥ç”Ÿæˆ")
    print(f"   2. ä¸­é—´å¤„ç†æ­¥éª¤çš„æµå¼äº‹ä»¶å¯¹ç”¨æˆ·ä»·å€¼ä¸å¤§")
    print(f"   3. è¿‡å¤šçš„ä¸­é—´äº‹ä»¶åè€Œå¢åŠ å¤æ‚åº¦")
    print(f"   4. æ­£ç¡®çš„æµå¼å“åº”åº”è¯¥èšç„¦åœ¨æœ€ç»ˆè¾“å‡º")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ­£ç¡®æµå¼å“åº”æ¦‚å¿µéªŒè¯")
    print("=" * 60)
    
    await test_streaming_approaches()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ æ€»ç»“")
    print("=" * 60)
    print("âœ… æ­£ç¡®çš„æµå¼å“åº”ç†è§£:")
    print("   - ä¸­é—´å¤„ç†è¿‡ç¨‹ä¸éœ€è¦æµå¼")
    print("   - åªæœ‰æœ€ç»ˆç­”æ¡ˆç”Ÿæˆéœ€è¦æµå¼")
    print("   - ç”¨æˆ·ä½“éªŒèšç„¦åœ¨çœ‹åˆ°ç­”æ¡ˆé€æ­¥å‡ºç°")
    print("   - å‡å°‘ä¸å¿…è¦çš„äº‹ä»¶å’Œå¤æ‚åº¦")
    print("\nâŒ é”™è¯¯çš„æµå¼å“åº”ç†è§£:")
    print("   - ä¸ºæ¯ä¸ªä¸­é—´æ­¥éª¤éƒ½è®¾è®¡æµå¼äº‹ä»¶")
    print("   - å¢åŠ äº†å®ç°å¤æ‚åº¦ä½†ç”¨æˆ·ä»·å€¼ä¸å¤§")
    print("   - è¿‡å¤šçš„çŠ¶æ€æ›´æ–°å¯èƒ½å¹²æ‰°ç”¨æˆ·ä½“éªŒ")


if __name__ == "__main__":
    asyncio.run(main())