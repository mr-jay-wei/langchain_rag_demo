#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FastAPI Web æœåŠ¡ - RAG ç³»ç»Ÿ API æ¥å£

æä¾› RESTful API æ¥å£ï¼Œå°† RAG Pipeline å°è£…ä¸º Web æœåŠ¡
æ”¯æŒé—®ç­”æŸ¥è¯¢ã€çŸ¥è¯†åº“ç®¡ç†ã€ç³»ç»Ÿç›‘æ§ç­‰åŠŸèƒ½
"""

import os
import time
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
import uvicorn

from rag.pipeline import RagPipeline
from rag import config


# ================================
# æ•°æ®æ¨¡å‹å®šä¹‰
# ================================

class QueryRequest(BaseModel):
    """æŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    query: str = Field(..., description="ç”¨æˆ·æŸ¥è¯¢é—®é¢˜", max_length=1000)
    categories: Optional[List[str]] = Field(default=None, description="æŒ‡å®šæœç´¢çš„æ–‡æ¡£ç±»åˆ«")
    options: Optional[Dict[str, Any]] = Field(default_factory=dict, description="æŸ¥è¯¢é€‰é¡¹")

class QueryOptions(BaseModel):
    """æŸ¥è¯¢é€‰é¡¹æ¨¡å‹"""
    enable_rewriting: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨é—®é¢˜æ”¹å†™")
    enable_hybrid_search: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨æ··åˆæ£€ç´¢")
    max_results: int = Field(default=5, description="æœ€å¤§è¿”å›ç»“æœæ•°", ge=1, le=20)
    timeout: int = Field(default=30, description="æŸ¥è¯¢è¶…æ—¶æ—¶é—´(ç§’)", ge=5, le=120)

class BatchQueryRequest(BaseModel):
    """æ‰¹é‡æŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    queries: List[QueryRequest] = Field(..., description="æŸ¥è¯¢åˆ—è¡¨", max_items=10)
    options: Optional[Dict[str, Any]] = Field(default_factory=dict, description="æ‰¹é‡æŸ¥è¯¢é€‰é¡¹")

class DocumentSource(BaseModel):
    """æ–‡æ¡£æ¥æºæ¨¡å‹"""
    content: str = Field(..., description="æ–‡æ¡£å†…å®¹ç‰‡æ®µ")
    source: str = Field(..., description="æ¥æºæ–‡ä»¶å")
    category: Optional[str] = Field(default=None, description="æ–‡æ¡£ç±»åˆ«")
    score: float = Field(..., description="ç›¸å…³æ€§è¯„åˆ†", ge=0.0, le=1.0)

class QueryResponse(BaseModel):
    """æŸ¥è¯¢å“åº”æ¨¡å‹"""
    success: bool = Field(..., description="è¯·æ±‚æ˜¯å¦æˆåŠŸ")
    data: Optional[Dict[str, Any]] = Field(default=None, description="å“åº”æ•°æ®")
    error: Optional[str] = Field(default=None, description="é”™è¯¯ä¿¡æ¯")
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat(), description="å“åº”æ—¶é—´æˆ³")

class KnowledgeStatus(BaseModel):
    """çŸ¥è¯†åº“çŠ¶æ€æ¨¡å‹"""
    total_documents: int = Field(..., description="æ–‡æ¡£æ€»æ•°")
    categories: Dict[str, int] = Field(..., description="å„ç±»åˆ«æ–‡æ¡£æ•°é‡")
    last_sync: Optional[str] = Field(default=None, description="æœ€ååŒæ­¥æ—¶é—´")
    vector_store_size: str = Field(..., description="å‘é‡æ•°æ®åº“å¤§å°")

class HealthStatus(BaseModel):
    """å¥åº·çŠ¶æ€æ¨¡å‹"""
    status: str = Field(..., description="æœåŠ¡çŠ¶æ€")
    version: str = Field(..., description="ç‰ˆæœ¬å·")
    uptime: int = Field(..., description="è¿è¡Œæ—¶é—´(ç§’)")
    components: Dict[str, str] = Field(..., description="ç»„ä»¶çŠ¶æ€")


# ================================
# å…¨å±€å˜é‡å’Œåˆå§‹åŒ–
# ================================

# æœåŠ¡å¯åŠ¨æ—¶é—´
SERVICE_START_TIME = time.time()

# RAG Pipeline å®ä¾‹
rag_pipeline: Optional[RagPipeline] = None

# æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
service_stats = {
    "queries_total": 0,
    "queries_success": 0,
    "queries_error": 0,
    "total_response_time": 0.0,
    "last_query_time": None
}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global rag_pipeline
    
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ RAG Web æœåŠ¡...")
    
    # åˆå§‹åŒ– RAG Pipeline
    try:
        rag_pipeline = RagPipeline()
        print("âœ… RAG Pipeline åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ RAG Pipeline åˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    print("ğŸŒ RAG Web æœåŠ¡å¯åŠ¨å®Œæˆ!")
    print(f"ğŸ“– API æ–‡æ¡£: http://localhost:8000/docs")
    print(f"ğŸ” ReDoc: http://localhost:8000/redoc")
    
    yield
    
    print("ğŸ›‘ æ­£åœ¨å…³é—­ RAG Web æœåŠ¡...")


# ================================
# FastAPI åº”ç”¨åˆå§‹åŒ–
# ================================

app = FastAPI(
    title="RAG ç³»ç»Ÿ API",
    description="ä¼ä¸šçº§æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿçš„ Web API æ¥å£",
    version="4.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ================================
# è¾…åŠ©å‡½æ•°
# ================================

def update_stats(success: bool, response_time: float):
    """æ›´æ–°æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    global service_stats
    service_stats["queries_total"] += 1
    service_stats["total_response_time"] += response_time
    service_stats["last_query_time"] = datetime.now().isoformat()
    
    if success:
        service_stats["queries_success"] += 1
    else:
        service_stats["queries_error"] += 1

def get_file_size_str(path: str) -> str:
    """è·å–æ–‡ä»¶å¤§å°çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
    if not os.path.exists(path):
        return "0B"
    
    size = sum(
        os.path.getsize(os.path.join(dirpath, filename))
        for dirpath, dirnames, filenames in os.walk(path)
        for filename in filenames
    )
    
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024.0:
            return f"{size:.1f}{unit}"
        size /= 1024.0
    return f"{size:.1f}TB"


# ================================
# API è·¯ç”±å®šä¹‰
# ================================

@app.get("/", summary="æ ¹è·¯å¾„", description="æœåŠ¡åŸºæœ¬ä¿¡æ¯")
async def root():
    """æ ¹è·¯å¾„ - è¿”å›æœåŠ¡åŸºæœ¬ä¿¡æ¯"""
    return {
        "service": "RAG ç³»ç»Ÿ API",
        "version": "4.0.0",
        "status": "running",
        "docs": "/docs",
        "redoc": "/redoc"
    }


@app.post("/api/v1/ask", response_model=QueryResponse, summary="é—®ç­”æŸ¥è¯¢", description="æ ¸å¿ƒé—®ç­”æ¥å£")
async def ask_question(request: QueryRequest):
    """
    æ ¸å¿ƒé—®ç­”æ¥å£
    
    æ”¯æŒä»¥ä¸‹åŠŸèƒ½:
    - æ™ºèƒ½é—®ç­”æŸ¥è¯¢
    - åˆ†ç±»æ£€ç´¢
    - æ··åˆæ£€ç´¢
    - é—®é¢˜æ”¹å†™
    """
    start_time = time.time()
    
    try:
        if not rag_pipeline:
            # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            response_time = time.time() - start_time
            update_stats(False, response_time)
            
            return QueryResponse(
                success=False,
                error="RAG Pipeline æœªåˆå§‹åŒ–ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜",
                data={
                    "answer": "æŠ±æ­‰ï¼Œç³»ç»Ÿæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                    "query_info": {
                        "original_query": request.query,
                        "categories": request.categories,
                        "search_time": round(time.time() - start_time, 2),
                        "status": "pipeline_not_ready"
                    }
                }
            )
        
        # è§£ææŸ¥è¯¢é€‰é¡¹
        options = request.options or {}
        
        # æ‰§è¡ŒæŸ¥è¯¢
        if request.categories:
            # åˆ†ç±»æŸ¥è¯¢
            result = rag_pipeline.ask_with_categories(
                query=request.query,
                categories=request.categories
            )
        else:
            # æ™®é€šæŸ¥è¯¢
            result = rag_pipeline.ask(request.query)
        
        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "answer": result,
            "query_info": {
                "original_query": request.query,
                "categories": request.categories,
                "search_time": round(time.time() - start_time, 2),
                "options": options,
                "status": "success"
            }
        }
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        response_time = time.time() - start_time
        update_stats(True, response_time)
        
        return QueryResponse(
            success=True,
            data=response_data
        )
        
    except Exception as e:
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        response_time = time.time() - start_time
        update_stats(False, response_time)
        
        # è¿”å›æ›´å‹å¥½çš„é”™è¯¯å“åº”
        return QueryResponse(
            success=False,
            error=f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}",
            data={
                "answer": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶å‡ºç°äº†é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "query_info": {
                    "original_query": request.query,
                    "categories": request.categories,
                    "search_time": round(time.time() - start_time, 2),
                    "status": "error"
                }
            }
        )


@app.post("/api/v1/ask/batch", response_model=QueryResponse, summary="æ‰¹é‡æŸ¥è¯¢", description="æ‰¹é‡é—®ç­”æ¥å£")
async def ask_batch(request: BatchQueryRequest):
    """
    æ‰¹é‡é—®ç­”æ¥å£
    
    æ”¯æŒåŒæ—¶å¤„ç†å¤šä¸ªæŸ¥è¯¢è¯·æ±‚
    """
    start_time = time.time()
    
    try:
        if not rag_pipeline:
            raise HTTPException(status_code=503, detail="RAG Pipeline æœªåˆå§‹åŒ–")
        
        results = []
        
        for query_req in request.queries:
            try:
                if query_req.categories:
                    result = rag_pipeline.ask_with_categories(
                        query=query_req.query,
                        categories=query_req.categories
                    )
                else:
                    result = rag_pipeline.ask(query_req.query)
                
                results.append({
                    "query": query_req.query,
                    "answer": result,
                    "success": True,
                    "error": None
                })
                
            except Exception as e:
                results.append({
                    "query": query_req.query,
                    "answer": None,
                    "success": False,
                    "error": str(e)
                })
        
        response_data = {
            "results": results,
            "total_queries": len(request.queries),
            "successful_queries": sum(1 for r in results if r["success"]),
            "total_time": round(time.time() - start_time, 2)
        }
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        response_time = time.time() - start_time
        update_stats(True, response_time)
        
        return QueryResponse(
            success=True,
            data=response_data
        )
        
    except Exception as e:
        response_time = time.time() - start_time
        update_stats(False, response_time)
        
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")


@app.get("/api/v1/knowledge/status", response_model=QueryResponse, summary="çŸ¥è¯†åº“çŠ¶æ€", description="è·å–çŸ¥è¯†åº“çŠ¶æ€ä¿¡æ¯")
async def get_knowledge_status():
    """è·å–çŸ¥è¯†åº“çŠ¶æ€ä¿¡æ¯"""
    try:
        # å¦‚æœ RAG Pipeline æœªåˆå§‹åŒ–ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
        if not rag_pipeline:
            return QueryResponse(
                success=True,
                data={
                    "total_documents": 0,
                    "categories": {},
                    "last_sync": None,
                    "vector_store_size": "0B",
                    "status": "pipeline_not_initialized"
                }
            )
        
        # è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
        categories = {}
        total_docs = 0
        
        try:
            if hasattr(rag_pipeline, 'get_available_categories'):
                categories = rag_pipeline.get_available_categories()
                total_docs = sum(categories.values()) if categories else 0
        except Exception as e:
            print(f"è·å–ç±»åˆ«ä¿¡æ¯å¤±è´¥: {e}")
            categories = {}
            total_docs = 0
        
        # è·å–å‘é‡æ•°æ®åº“å¤§å°
        try:
            vector_store_path = getattr(config, 'VECTOR_STORE_PATH', './my_chromadb_vector_store')
            vector_store_size = get_file_size_str(vector_store_path)
        except Exception as e:
            print(f"è·å–å‘é‡æ•°æ®åº“å¤§å°å¤±è´¥: {e}")
            vector_store_size = "unknown"
        
        status_data = {
            "total_documents": total_docs,
            "categories": categories,
            "last_sync": None,  # å¯ä»¥ä»é…ç½®æˆ–æ—¥å¿—ä¸­è·å–
            "vector_store_size": vector_store_size,
            "status": "ready"
        }
        
        return QueryResponse(
            success=True,
            data=status_data
        )
        
    except Exception as e:
        # è¿”å›é”™è¯¯ä¿¡æ¯ä½†ä¸æŠ›å‡ºå¼‚å¸¸
        return QueryResponse(
            success=False,
            error=f"è·å–çŸ¥è¯†åº“çŠ¶æ€å¤±è´¥: {str(e)}",
            data={
                "total_documents": 0,
                "categories": {},
                "last_sync": None,
                "vector_store_size": "unknown",
                "status": "error"
            }
        )


@app.post("/api/v1/knowledge/sync", response_model=QueryResponse, summary="åŒæ­¥çŸ¥è¯†åº“", description="æ‰‹åŠ¨è§¦å‘çŸ¥è¯†åº“åŒæ­¥")
async def sync_knowledge_base(background_tasks: BackgroundTasks):
    """æ‰‹åŠ¨è§¦å‘çŸ¥è¯†åº“åŒæ­¥"""
    try:
        if not rag_pipeline:
            raise HTTPException(status_code=503, detail="RAG Pipeline æœªåˆå§‹åŒ–")
        
        # åœ¨åå°æ‰§è¡ŒåŒæ­¥ä»»åŠ¡
        def sync_task():
            try:
                rag_pipeline.sync_data_directory()
                print("âœ… çŸ¥è¯†åº“åŒæ­¥å®Œæˆ")
            except Exception as e:
                print(f"âŒ çŸ¥è¯†åº“åŒæ­¥å¤±è´¥: {e}")
        
        background_tasks.add_task(sync_task)
        
        return QueryResponse(
            success=True,
            data={
                "message": "çŸ¥è¯†åº“åŒæ­¥ä»»åŠ¡å·²å¯åŠ¨",
                "status": "running"
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨çŸ¥è¯†åº“åŒæ­¥å¤±è´¥: {str(e)}")


@app.get("/api/v1/health", response_model=QueryResponse, summary="å¥åº·æ£€æŸ¥", description="æœåŠ¡å¥åº·çŠ¶æ€æ£€æŸ¥")
async def health_check():
    """æœåŠ¡å¥åº·çŠ¶æ€æ£€æŸ¥"""
    try:
        uptime = int(time.time() - SERVICE_START_TIME)
        
        # æ£€æŸ¥å„ç»„ä»¶çŠ¶æ€ï¼ˆæ›´å®½æ¾çš„æ£€æŸ¥ï¼‰
        components = {}
        
        # æ£€æŸ¥ RAG Pipeline
        if rag_pipeline:
            components["rag_pipeline"] = "healthy"
        else:
            components["rag_pipeline"] = "initializing"
        
        # æ£€æŸ¥å‘é‡å­˜å‚¨è·¯å¾„
        try:
            vector_store_path = getattr(config, 'VECTOR_STORE_PATH', './my_chromadb_vector_store')
            components["vector_store"] = "healthy" if os.path.exists(vector_store_path) else "not_found"
        except:
            components["vector_store"] = "unknown"
        
        # æ£€æŸ¥æ•°æ®ç›®å½•
        try:
            data_directory = getattr(config, 'DATA_DIRECTORY', './data')
            components["data_directory"] = "healthy" if os.path.exists(data_directory) else "not_found"
        except:
            components["data_directory"] = "unknown"
        
        # åˆ¤æ–­æ•´ä½“çŠ¶æ€ï¼ˆæ›´å®½æ¾çš„åˆ¤æ–­ï¼‰
        critical_components = ["rag_pipeline"]
        overall_status = "healthy"
        
        for component in critical_components:
            if components.get(component) == "unhealthy":
                overall_status = "unhealthy"
                break
        
        if components.get("rag_pipeline") == "initializing":
            overall_status = "initializing"
        
        health_data = {
            "status": overall_status,
            "version": "4.0.0",
            "uptime": uptime,
            "components": components
        }
        
        return QueryResponse(
            success=True,
            data=health_data
        )
        
    except Exception as e:
        # å³ä½¿å‡ºé”™ä¹Ÿè¿”å›åŸºæœ¬ä¿¡æ¯ï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        return QueryResponse(
            success=False,
            error=f"å¥åº·æ£€æŸ¥éƒ¨åˆ†å¤±è´¥: {str(e)}",
            data={
                "status": "error",
                "version": "4.0.0",
                "uptime": int(time.time() - SERVICE_START_TIME),
                "components": {"error": str(e)}
            }
        )


@app.get("/api/v1/metrics", response_model=QueryResponse, summary="æœåŠ¡æŒ‡æ ‡", description="è·å–æœåŠ¡è¿è¡ŒæŒ‡æ ‡")
async def get_metrics():
    """è·å–æœåŠ¡è¿è¡ŒæŒ‡æ ‡"""
    try:
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        avg_response_time = 0.0
        if service_stats["queries_total"] > 0:
            avg_response_time = service_stats["total_response_time"] / service_stats["queries_total"]
        
        # è®¡ç®—é”™è¯¯ç‡
        error_rate = 0.0
        if service_stats["queries_total"] > 0:
            error_rate = service_stats["queries_error"] / service_stats["queries_total"]
        
        metrics_data = {
            "queries_total": service_stats["queries_total"],
            "queries_success": service_stats["queries_success"],
            "queries_error": service_stats["queries_error"],
            "average_response_time": round(avg_response_time, 2),
            "error_rate": round(error_rate, 4),
            "last_query_time": service_stats["last_query_time"],
            "uptime": int(time.time() - SERVICE_START_TIME)
        }
        
        return QueryResponse(
            success=True,
            data=metrics_data
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æœåŠ¡æŒ‡æ ‡å¤±è´¥: {str(e)}")


# ================================
# ä¸»ç¨‹åºå…¥å£
# ================================

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ RAG Web æœåŠ¡...")
    print("ğŸ“– API æ–‡æ¡£å°†åœ¨ http://localhost:8000/docs æä¾›")
    print("ğŸ” ReDoc æ–‡æ¡£å°†åœ¨ http://localhost:8000/redoc æä¾›")
    print("âš¡ ä½¿ç”¨ Ctrl+C åœæ­¢æœåŠ¡")
    
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # å¼€å‘æ¨¡å¼ï¼Œç”Ÿäº§ç¯å¢ƒåº”è®¾ä¸º False
        log_level="info"
    )